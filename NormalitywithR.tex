\section{Testing regression residuals for normality}
\subsection{Residual}  The difference between the predicted value (based on the regression equation) and the actual, observed value. In simple linear regression models, the matter of whether or not residuals are normally distributed often arises.
\subsection{Outlier}  In linear regression, an outlier is an observation with large residual.  In other words, it is an observation whose dependent-variable value is unusual given its values on the predictor variables.  An outlier may indicate a sample peculiarity or may indicate a data entry error or other problem.
\subsection{Leverage}  An observation with an extreme value on a predictor variable is a point with high leverage.  Leverage is a measure of how far an independent variable deviates from its mean.  These leverage points can have an effect on the estimate of regression coefficients.
\subsection{Influence}  An observation is said to be influential if removing the observation substantially changes the estimate of coefficients.  Influence can be thought of as the product of leverage and outlierness.


\subsubsection{Grubbs Test for outliers}
\subsection{Anderson Darling Test}
\subsection{Normal Probability plots}
\subsubsection{ Kolmogorov Smirnov Test}
