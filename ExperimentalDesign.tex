MA4605 Experimental Design ( Intro )
In an experiment study, various treatments are applied to test subjects and the response data is gathered for analysis. A critical tool for carrying out the analysis is the Analysis of Variance (ANOVA). It enables a researcher to differentiate treatment results based on easily computed statistical quantities from the treatment outcome.

The statistical process is derived from estimates of the population variances via two separate approaches. The first approach is based on the variance of the sample means, and the second one is based on the mean of the sample variances. 

Under the ANOVA assumptions as stated below, the ratio of the two statistical estimates follows the F distribution. Hence we can test the null hypothesis on the equality of various response data from different treatments via estimates of critical regions.

•	The treatment responses are independent of each other.
•	The response data follow the normal distribution.
•	The variances of the response data are identical.

Experimentation
An experiment deliberately imposes a treatment on a group of objects or subjects in the interest of observing the response. This differs from an observational study, which involves collecting and analyzing data without changing existing conditions. Because the validity of a experiment is directly affected by its construction and execution, attention to experimental design is extremely important.
Treatment
In experiments, a treatment is something that researchers administer to experimental units. For example, a corn field is divided into four, each part is 'treated' with a different fertiliser to see which produces the most corn; a teacher practices different teaching methods on different groups in her class to see which yields the best results; a doctor treats a patient with a skin condition with different creams to see which is most effective. 
Treatments are administered to experimental units by 'level', where level implies amount or magnitude. For example, if the experimental units were given 5mg, 10mg, 15mg of a medication, those amounts would be three levels of the treatment. 
Factor
A factor of an experiment is a controlled independent variable; a variable whose levels are set by the experimenter.
A factor is a general type or category of treatments. Different treatments constitute different levels of a factor. For example, three different groups of runners are subjected to different training methods. The runners are the experimental units, the training methods, the treatments, where the three types of training methods constitute three levels of the factor 'type of training'. 
Types of Effects 
An effect is a change in the response due to a change in a factor level.  There are different types of effects.  One objective of an experiment is to determine if there are significant differences in the responses across levels of a treatment (a fixed effect) or any interaction  between the treatment levels.  If this is always the case, the analysis is usually easily  manageable, given that the anomalies in the data are minimal (outliers, missing data,  homogeneous variances, unbalanced sample sizes, and so on). 
A random effect exists when the levels that are chosen represent a random selection from a much larger population of equally usable levels. This is often thought of as a sample of interchangeable individuals or conditions.  The chosen levels represent arbitrary realisations from a much larger set of other equally acceptable levels.  Elements of the design structure (for example, the blocks) are usually treated as random  effects.  Blocks are a sub-set of the larger set of blocks over which inference is to be made.  It  is helpful to assume that there is no interaction among elements of the design structure and  elements of the treatment structure if blocks are considered a fixed effect.  If blocks are treated as random effects, you can determine interaction among elements of treatment structure and  design structure. 
The number of potential human subjects that are available is often very large compared to the actual number of subjects that are used.  Subjects who are chosen are likely to be just as reasonable to collect data from as potential subjects who were not chosen, and inferences for how individual subjects respond is usually not of primary importance, whereas a measure of the variation in responses is important to know. 
One additional consideration that is essential in the evaluation of the treatment and design structure with two or more treatment/design factors is to differentiate whether the levels of the factors are either crossed or nested with each other. Two factors that are crossed with one another means that all levels of the first factor appear in combination with all levels of the second factor, which produces all possible combinations.  For example, in an education program, male and female students receive the same educational tests, thus, gender is crossed with test. 
One factor that is nested in a second factor implies a hierarchy.  This means that a given level of the nested factor appears in one level of the nesting factor.  For example, in a study of educational programs, teachers are usually nested within schools because, usually, teachers teach only at one school.
Completely Randomized Design
In a completely randomized design, objects or subjects are assigned to groups completely at random. One standard method for assigning subjects to treatment groups is to label each subject, then use a table of random numbers to select from the labelled subjects. This may also be accomplished using a computer. 
Randomized Block Design
If an experimenter is aware of specific differences among groups of subjects or objects within an experimental group, he or she may prefer a randomized block design to a completely randomized design. In a block design, experimental subjects are first divided into homogeneous blocks before they are randomly assigned to a treatment group. If, for instance, an experimenter had reason to believe that age might be a significant factor in the effect of a given medication, he might choose to first divide the experimental subjects into age groups, such as under 30 years old, 30-60 years old, and over 60 years old. 
Then, within each age level, individuals would be assigned to treatment groups using a completely randomized design. 
In a block design, both control and randomization are considered.
Example
A researcher is carrying out a study of the effectiveness of four different skin creams for the treatment of a certain skin disease. He has eighty subjects and plans to divide them into 4 treatment groups of twenty subjects each. 
Using a randomized block design, the subjects are assessed and put in blocks of four according to how severe their skin condition is; the four most severe cases are the first block, the next four most severe cases are the second block, and so on to the twentieth block. The four members of each block are then randomly assigned, one to each of the four treatment groups. 


Design of Experiments
•	Randomised blocks
•	Latin Square Design
•	Factorials
•	Analysis of Variance
•	Economy of Experiments
•	Factors
•	Box Behnken Design
There are four ways to collect data for an analysis.
1)	Obtain historical data
2)	Collect new data
3)	Run specific experiments by disturbing (exciting) the system being studied.
4)	Design experiments in a structured mathematical way.
DoE is a useful complement to multivariate data analysis because it generates  structured data tables, i.e. data that contains important amounts of structured variation.

•	Completely Randomised Design
•	Randomised Complete Block Design
•	Factorial Design
•	One Way Analysis of Variance
•	Two Way Analysis of Variance
 
Experimental Design 
We are concerned with the analysis of data generated from an experiment. It is wise to take time and effort to organise the experiment properly to ensure that the right type of data, and enough of it, is available to answer the questions of interest as clearly and efficiently as possible. This process is called experimental design.
The specific questions that the experiment is intended to answer must be clearly identified before carrying out the experiment. We should also attempt to identify known or expected sources of variability in the experimental units since one of the main aims of a designed experiment is to reduce the effect of these sources of variability on the answers to questions of interest. That is, we design the experiment in order to improve the precision of our answers.
Treatment 
In experiments, a treatment is something that researchers administer to experimantal units . For example, a corn field is divided into four, each part is 'treated' with a different fertiliser to see which produces the most corn; a teacher practices different teaching methods on different groups in her class to see which yields the best results; a doctor treats a patient with a skin condition with different creams to see which is most effective.
Treatments are administered to experimental units by 'level', where level implies amount or magnitude. For example, if the experimental units were given 5mg, 10mg, 15mg of a medication, those amounts would be three levels of the treatment. 'Level' is also used for categorical variables, such as Drugs A, B, and C, where the three are different kinds of drug, not different amounts of the same thing.
Factor 
A factor of an experiment is a controlled independent variable; a variable whose levels are set by the experimenter.
A factor is a general type or category of treatments. Different treatments constitute different levels of a factor. For example, three different groups of runners are subjected to different training methods. The runners are the experimental units, the training methods, the treatments, where the three types of training methods constitute three levels of the factor 'type of training'.
One Way Analysis of Variance 
The one way analysis of variance allows us to compare several groups of observations, all of which are independent but possibly with a different mean for each group. A test of great importance is whether or not all the means are equal.
The observations all arise from one of several different groups (or have been exposed to one of several different treatments in an experiment). We are classifying 'one-way' according to the group or treatment.
Two Way Analysis of Variance 
Two Way Analysis of Variance is a way of studying the effects of two factors separately (their main effects) and (sometimes) together (their interaction effect).

Completely Randomised Design 
The structure of the experiment in a completely randomised design is assumed to be such that the treatments are allocated to the experimental units completely at random.
Randomised Complete Block Design 
The randomised complete block design is a design in which the subjects are matched according to a variable which the experimenter wishes to control. The subjects are put into groups (blocks) of the same size as the number of treatments. The members of each block are then randomly assigned to different treatment groups.
Example 
A researcher is carrying out a study of the effectiveness of four different skin creams for the treatment of a certain skin disease. He has eighty subjects and plans to divide them into 4 treatment groups of twenty subjects each. Using a randomised blocks design, the subjects are assessed and put in blocks of four according to how severe their skin condition is; the four most severe cases are the first block, the next four most severe cases are the second block, and so on to the twentieth block. The four members of each block are then randomly assigned, one to each of the four treatment groups.
Factorial Design 
A factorial design is used to evaluate two or more factors simultaneously. The treatments are combinations of levels of the factors. The advantages of factorial designs over one-factor-at-a-time experiments is that they are more efficient and they allow interactions to be detected.
Main Effect 
This is the simple effect of a factor on a dependent variable. It is the effect of the factor alone averaged across the levels of other factors.
Example 
A cholesterol reduction clinic has two diets and one exercise regime. It was found that exercise alone was effective, and diet alone was effective in reducing cholesterol levels (main effect of exercise and main effect of diet). Also, for those patients who didn't exercise, the two diets worked equally well (main effect of diet); those who followed diet A and exercised got the benefits of both (main effect of diet A and main effect of exercise). However, it was found that those patients who followed diet B and exercised got the benefits of both plus a bonus, an interaction effect (main effect of diet B, main effect of exercise plus an interaction effect).
Interaction 
An interaction is the variation among the differences between means for different levels of one factor over different levels of the other factor.
Example 
A cholesterol reduction clinic has two diets and one exercise regime. It was found that exercise alone was effective, and diet alone was effective in reducing cholesterol levels (main effect of exercise and main effect of diet). Also, for those patients who didn't exercise, the two diets worked equally well (main effect of diet); those who followed diet A and exercised got the benefits of both (main effect of diet A and main effect of exercise). However, it was found that those patients who followed diet B and exercised got the benefits of both plus a bonus, an interaction effect (main effect of diet B, main effect of exercise plus an interaction effect).
Randomisation 
Randomisation is the process by which experimental units (the basic objects upon which the study or experiment is carried out) are allocated to treatments; that is, by a random process and not by any subjective and hence possibly biased approach. The treatments should be allocated to units in such a way that each treatment is equally likely to be applied to each unit.
Randomisation is preferred since alternatives may lead to biased results.
The main point is that randomisation tends to produce groups for study that are comparable in unknown as well as known factors likely to influence the outcome, apart from the actual treatment under study. The analysis of variance F tests assume that treatments have been applied randomly.
Blinding 
In a medical experiment, the comparison of treatments may be distorted if the patient, the person administering the treatment and those evaluating it know which treatment is being allocated. It is therefore necessary to ensure that the patient and/or the person administering the treatment and/or the trial evaluators are 'blind to' (don't know) which treatment is allocated to whom.
Sometimes the experimental set-up of a clinical trial is referred to as double-blind, that is, neither the patient nor those treating and evaluating their condition are aware (they are 'blind' as to) which treatment a particular patient is allocated. A double-blind study is the most scientifically acceptable option.
Sometimes however, a double-blind study is impossible, for example in surgery. It might still be important though to have a single-blind trial in which the patient only is unaware of the treatment received, or in other instances, it may be important to have blinded evaluation.
Placebo 
A placebo is an inactive treatment or procedure. It literally means 'I do nothing'. The 'placebo effect' (usually a positive or beneficial response) is attributable to the patient's expectation that the treatment will have an effect.
Blocking 
This is the procedure by which experimental units are grouped into homogeneous clusters in an attempt to improve the comparison of treatments by randomly allocating the treatments within each cluster or 'block'.

Six Sigma 
Six Sigma at many organizations simply means a measure of quality that strives for near perfection. Six Sigma is a disciplined,  data-driven approach and methodology for eliminating defects (driving 
toward six standard deviations between the mean and the nearest specification limit) in any process – from manufacturing to transactional and from product to service. The statistical representation of Six Sigma describes quantitatively how a process is performing. To achieve Six Sigma, a process must not produce more than 3.4 defects per million opportunities. A Six Sigma defect is defined as anything outside of customer specifications. A Six Sigma opportunity is then the total quantity of chances for a defect. The fundamental objective of the Six Sigma methodology is the implementation of a measurement-based strategy that focuses on process improvement and variation reduction through the application of Six Sigma improvement projects. 
This is accomplished through the use of two Six Sigma sub-methodologies: DMAIC and DMADV.  The Six Sigma DMAIC process (define, measure, analyze, improve, control) is an improvement system for existing processes falling below specification and looking for incremental improvement. 
The Six Sigma DMADV process (define, measure, analyze, design, verify) is an improvement system used to develop new processes or products at Six Sigma quality levels. It can also be employed if a current process requires more than just incremental improvement.
Both Six Sigma processes are executed by Six Sigma Green Belts and Six Sigma Black Belts, and are overseen by Six Sigma Master Black Belts.
Linear Models

•	Simple Linear Regression 
o	Checking Model Assumptions
o	Inferences
o	Deming Regression / Orthogonal Regression / Error in Variable Models
o	Prediction Intervals
?	Equivalence of tests for slope and correlation 
o	Diagnostics
o	Residuals
•	Multiple Linear Regression
o	Revision of Linear Algebra
o	The Hat Matrix
o	Leave one out (Sherman-Woodbury)
•	Variable Selection Procedures
o	Law of Parsimony
o	Stepwise Regression
o	Forward Selection
o	Backward Elimination
o	The F Distribution
•	Diagnostics
o	Cook’s Distance

